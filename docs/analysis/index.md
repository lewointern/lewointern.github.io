---
title: 1.基本介绍
---

##### HAWQ-DB 是世界上首个能够原生运行在 PaaS 平台中的高性能 MPP++分析型数据库。 <br><br>HAWQ-DB 完整兼容 ANSI-SQL 标准, 提供对 Hadoop 上 PB 级数据的高性能交互式查询能力,并且提供对主要 BI 工具的描述性分析支持。
___
### 主要功能* 公有云和私有云部署:支持亚马逊和阿里云等公有云平台,同时可以支持主流 PaaS 云平台(比如 Kubernetes 等)和 Docker 部署。* 对标准的完善支持:ANSI SQL 标准,OLAP 扩展,标准 JDBC/ODBC,比其他 Hadoop SQL 引擎都要完善。* 具有 MPP(大规模并行处理系统)的性能,比其他 Hadoop 里面的 SQL 引擎快数 倍。但比传统 MPP 引擎更加灵活,比如秒级扩容以及 PaaS 平台原生集成的能力。* 具有非常成熟的并行优化器。优化器是并行 SQL 引擎的重要组成部分,对性能影响很大,尤其是对复杂查询。* 支持 ACID 事务特性:这是很多现有基于 Hadoop 的 SQL 引擎做不到的,对保证数据一致性很重要。可以有效减少开发及运维人员的负担。* 动态数据流引擎:基于 UDP 的高速互联网络。* 弹性执行引擎:可以根据查询大小来决定执行查询使用的节点及 Segment 个数。* 支持多种分区方法及多级分区:支持 List 分区和 Range 分区。分区表对性能有很大提升作用,如果用户只想访问最近一个月的热数据,查询只需要扫描最近一个月数据所在分区。* 支持多种压缩方法:snappy,gzip,quicklz,RLE 等。* 多种存储过程语言支持:java, python, c/c++, perl, R 等。* 动态扩容:动态按需扩容,按照存储大小或者计算需求,秒级添加节点。* 多级资源和负载管理:和外部资源管理器 YARN 集成;可以管理 CPU,Memory 资源等;支持多级资源队列;具有方便的 DDL 管理接口。* 支持访问任何 HDFS 及其他系统的数据:各种 HDFS 格式(文本,SequenceFile,Avro,Parquet 等等)以及其他外部系统(HBase 等),并且用户自己可以开发插件来访问新的数据源。* 原生的机器学习数据挖掘库 MADLib 支持:易于使用及高性能。* 与 Hadoop 系统无缝集成:存储、资源、安装部署、数据格式和访问等。* 完善的安全及权限管理:kerberos;数据库,表等各个级别的授权管理。* 支持多种第三方工具:比如 Tableau,SAS,较新的 Apache Zeppelin 等。* 支持对 HDFS 和 YARN 的快速访问库:libhdfs3 和 libyarn(其他项目也可以使用)。
___## 2.HAWQ-DB 与云的结合

HAWQ-DB 支持在主流 Kubernetes PaaS 平台的安装部署。<br><br>HAWQ-DB 服务运行在 PaaS 平台管理的 Docker 容器中。在 Kubernetes 上部署 HAWQ-DB 和部署其它应用集群一样。都可以通过 Dashboard 用户界面或者命令行进行部署。<br><br>用户也可以像管理其他 PaaS 平台的应用程序一样来管理 HAWQ-DB 集群。

### HAWQ-DB 与云平台结合的优势和其他传统数据仓库相比,在 PaaS 平台上的 HAWQ-DB 具有如下功能及优势:
* 应用和服务一体化:不需要采取大数据服务外挂(不运行在 PaaS 平台中)的方 法,避免了大数据服务单独外挂带来的管理以及运维的复杂度。* 弹性扩容和自恢复:可以根据工作负载进行弹性扩容,并且当一个容器死掉以后, 可以重启容器。* 滚动升级:对小版本的升级可以采取滚动更新的方式来减少版本升级对系统的影 响。* 资源管理(计算/内存/IO):通过 PaaS 平台编排以及容器可以实现 HAWQ-DB 集群 以及其他运行在同一个物理集群上的系统的隔离。* 自动化运维:系统的安装部署和运维都比较自动化,简化了运维人员的工作,避免了很多手工操作。### HAWQ-DB 在 PaaS 平台的部署
	kubectl create configmap hadoop-config --from-file=hadoop-env.sh --from-file=slaves --from-file=core-site.xml --from-file=hdfs-site.xml
	kubectl create -f hdfs-nn.yam
	
	kubectl create -f hdfs-dn.yaml	kubectl create configmap hawq-config --from-file=hawq-site.xml --from-file=hdfs-client.xml
	kubectl create -f hawq-master.yaml
	kubectl create -f hawq-segment.yaml
	
## 3.体系结构
![06](/images/docs/06.png)
<br>图 1 给出了一个典型的 HAWQ-DB 集群的主要组件。<br><br>其中有几个 Master 节点:包括 HAWQ-DB master 节点,HDFS master 节点 NameNode,YARN master 节点 ResourceManager。<br><br>现在 HAWQ-DB 元数据服务在 HAWQ-DB master 节点里面,未来版本会成为单独的服务。<br><br>其他节点为 Slave 节点。每个 Slave 节点上部署有 HDFS DataNode,YARN NodeManager 以及一个 HAWQ-DB Segment。其中 YARN 是可选组 件,如果没有 YARN 的话,HAWQ 会使用自己内置的资源管理器。<br><br>HAWQ-DB Segment 在执行查询的时候会启动多个 QE (Query Executor, 查询执行器)。查询执行器运行在资源容器里面。在这个架构下,节点可以动态的加入集群,并且不需要数据重新分布。当一个节点加入集群时,他会向 HAWQ-DB Master 节点发送心跳,然后就可以接收未来查询了。
![07](/images/docs/07.png)
<br>图 2 是 HAWQ-DB 内部架构图。<br><br>可以看到在 HAWQ-DB master 节点内部有如下几个重要组件:查询解析器(Parser/Analyzer),优化器,资源管理器,资源代理,容错服务,查询派遣器,元数据服务。<br><br>在 Slave 节点上安装有一个物理 Segment,在查询执行时,针对一个查询,弹性执行引擎会启动多个虚拟 Segment 同时执行查询,节点间数据交换通过 Interconnect(高速互联网络)进行。<br><br>如果一个查询启动了 1000 个虚拟 Segment,意思是这个查询被均匀的分成了 1000 份任务,这些任务会并行执行。所以说虚拟 Segment 数其实表明了查询的并行度。查询的并行度是由弹性执行引擎根据查询大小以及当前资源使用情况动态确定的。<br>
<br><br>
下面我逐个来解释这些组件的作用以及它们之间的关系:

* 查询解析器:负责解析查询,并检查语法及语义。最终生成查询树传递给优化器。* 优化器:负责接受查询树,生成查询计划。针对一个查询,可能有数亿个可能的等价的查询计划,但执行性能差别很大。优化器的作用是找出优化的查询计划。* 资源管理器:资源管理器通过资源代理向全局资源管理器(比如YARN)动态申请资源并缓存资源。在不需要的时候返回资源。我们缓存资源的主要原因是减少 HAWQ-DB 与全局资源管理器之间的交互代价。HAWQ-DB 支持毫秒级查询。如果每一个小的查询都去向资源管理器申请资源,这样的话,性能会受到影响。资源管理器同时需要保证查询不使用超过分配给该查询的资源,否则查询之间会相互影响,可能导致系统整体不可用。
* HDFS 元数据缓存:用于 HAWQ-DB 确定哪些 Segment 扫描表的哪些部分。HAWQ-DB 需要把计算派遣到数据所在的地方,所以我们需要匹配计算和数据的局部 性。这些需要 HDFS 块的位置信息。位置信息存储在 HDFS NameNode 上。每个查 询都访问 HDFS NameNode 会造成 NameNode 的瓶颈。所以我们在 HAWQ-DB Master 节点上建立了 HDFS 元数据缓存。* 容错服务:负责检测哪些节点可用,哪些节点不可用。不可用的机器会被排除出资源池。* 查询派遣器:优化器优化完查询以后,查询派遣器派遣计划到各个节点上执行,并协 调查询执行的整个过程。查询派遣器是整个并行系统的粘合剂。* 元数据服务:负责存储 HAWQ-DB 的各种元数据,包括数据库和表信息,以及访问 权限信息等。另外,元数据服务也是实现分布式事务的关键。* 高速互联网络:负责在节点之间传输数据。使用软件实现,基于 UDP 协议。UDP 协 议无需建立连接,从而可以避免 TCP 高并发连接数的限制。
### 查询执行流程 
![08](/images/docs/08.png)<br>
用户通过 JDBC/ODBC 提交查询之后,查询解析器解析查询得到查询树,然后优化器根据查询树生成查询计划,派遣器和资源管理器交互得到资源,分解查询计划,然后派遣计划到 Segment 的执行器上面执行。最终结果会传回给用户。
### 弹性执行引擎
弹性执行引擎有几个关键设计点:存储和计算的完全分离,无状态 Segment 以及如何使用资源。<br><br>存储和计算的分离使得我们可以动态的启动任意多个虚拟 Segment 来执行查询。无状态 Segment 使得集群更容易扩展。要想保证大规模集群的状态一致性是比较困难的问题,所以我们采用了无状态的 Segment。<br><br>如何使用资源包括如何根据查询的代价申请多少资源,如何有效的使用这些资源以及如何使得数据局部性最优。<br><br>HAWQ-DB 内部针对每一个部分都进行了优化的设计。### 高速互联网络
高速互联网络的作用是在多个节点之间交换大量数据。HAWQ-DB 高速互联网络基于 UDP 协议。<br><br>大家可能会疑问为什么 HAWQ-DB 不使用 TCP。其实 HAWQ-DB 同时支持 TCP 和 UDP 两种协议,TCP 协议实现早于 UDP 协议。但是因为我们遇到了 TCP 不能很 好解决的高连接数并发问题,我们才开发了基于 UDP 的协议。<br><br>图 4 展示了一个高速互联网络的例子。
![09](/images/docs/09.png)
<br><br>例子中各个节点上的执行器进程形成了一个数据交换的流水线。<br><br>假设每个节点上有 1000 个进程。有 1000 个节点,这些进程需要相互交互,每个节点上就会有上百万个连接。 <br><br>TCP 是没办法高效地支持这么多的连接数的。所以我们开发了基于 UDP 的互联协议。针对 UDP 传输,操作系统是不能保证可靠性的,并且不能保证是有序传递的。<br><br>所以我们的设计需要保证和支持如下特性:
* 可靠性:能够保证在丢包的情况下,重传丢失的包* 有序性:保证包传递给接受者的最终有序性* 流量控制:如果不控制发送者的速度,接收者可能会被淹没,甚至会导致整个网络性能急剧下降* 性能和可扩展性:性能和可扩展性是我们需要解决 TCP 问题的初衷* 可支持多种平台
(详细信息可以查看参考文献。)
### 事务管理
事务是数据管理系统一个非常重要的属性。大部分 Hadoop 里面的 SQL 引擎不支持事务。让程序员自己保证事务和数据的一致性是非常困难的事。<br><br>HAWQ-DB 支持事务的所有 ACID 属性,支持 Snapshot Isolation。事务发生由 Master 节点协调和控制。采用的是泳道模型。并发插入时每个并发会使用各自的泳道,互不冲突。 
<br><br>在事务提交的时候通过记录文件逻辑长度的方式来保证一致性。如果事务失败的时候,需要回滚,删除文件末尾的垃圾数据。<br><br>起初 HDFS 是不支持 truncate 的,现在 HDFS 刚支持的 truncate 功能是根据 HAWQ-DB 的需求做出的。

### 资源管理器
HAWQ-DB 支持三级资源管理:

* 全局资源管理:可以集成 YARN,和其他系统共享集群资源。* HAWQ-DB 内部资源管理:可以支持查询,用户等级别的资源管理。* 操作符级别资源管理:可以针对操作符分配和强制资源使用。
现在 HAWQ-DB 支持多极资源队列。可以通过 DDL 方便的定义和修改资源队列。<br><br>下面是 HAWQ-DB 资源管理器的主要架构图(图 5):![10](/images/docs/10.png)
<br>资源管理器中的各个组件作用如下:1. 请求处理器:接收查询派遣器进程的资源请求。2. 资源分配器:负责资源的分配。3. 资源池:保存所有资源的现有状态。4. 策略存储:保存所有的分配策略,将来会做到策略可定制。 
5. 资源代理:负责与全局资源管理器交互。

### 存储模块
HAWQ-DB 支持多种内部优化的存储格式,比如 AO 和 Parquet。<br><br>提供 MapReduce InputFormat,可以供外部系统直接访问。其他各种存储格式通过扩展框架访问。<br><br>针对用户专有格式,用户可以自己开发插件。同时支持各种压缩,多极分区等各种功能。

## 4. 参考文献
 [1] Lei Chang et al: HAWQ: a massively parallel processing SQL engine in hadoop. . SIGMOD Conference   2014: 1223-1234